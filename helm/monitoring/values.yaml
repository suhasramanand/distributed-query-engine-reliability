# Default values for monitoring stack Helm chart

# Prometheus configuration
prometheus:
  enabled: true
  replicaCount: 1
  
  image:
    repository: prom/prometheus
    tag: "v2.47.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 9090
  
  resources:
    limits:
      cpu: 2000m
      memory: 4Gi
    requests:
      cpu: 1000m
      memory: 2Gi
  
  storage:
    enabled: true
    storageClass: "gp2"
    size: 100Gi
  
  config:
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - /etc/prometheus/rules/*.yml
    
    scrape_configs:
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
      
      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https
      
      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
      
      # Kubernetes pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
      
      # Presto/Trino metrics
      - job_name: 'presto'
        static_configs:
          - targets: ['presto-coordinator:8080', 'presto-worker:8080']
        metrics_path: /v1/metrics
        scrape_interval: 30s
      
      # ClickHouse metrics
      - job_name: 'clickhouse'
        static_configs:
          - targets: ['clickhouse:8123']
        metrics_path: /metrics
        scrape_interval: 30s
      
      # Spark metrics
      - job_name: 'spark'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: spark
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
            replacement: /metrics
      
      # Node Exporter
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
        static_configs:
          - targets: ['node-exporter:9100']
  
  rules:
    # Query engine alerts
    - name: query-engine-alerts
      rules:
        - alert: QueryEngineHighLatency
          expr: histogram_quantile(0.95, rate(query_duration_seconds_bucket[5m])) > 10
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Query engine high latency detected"
            description: "95th percentile query latency is above 10 seconds"
        
        - alert: QueryEngineHighErrorRate
          expr: rate(query_errors_total[5m]) > 0.1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Query engine high error rate detected"
            description: "Error rate is above 10%"
        
        - alert: QueryEngineHighMemoryUsage
          expr: (container_memory_usage_bytes{container!=""} / container_spec_memory_limit_bytes{container!=""}) > 0.85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Query engine high memory usage detected"
            description: "Memory usage is above 85%"
        
        - alert: QueryEngineHighCPUUsage
          expr: (rate(container_cpu_usage_seconds_total{container!=""}[5m]) * 100) > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Query engine high CPU usage detected"
            description: "CPU usage is above 80%"

# Grafana configuration
grafana:
  enabled: true
  replicaCount: 1
  
  image:
    repository: grafana/grafana
    tag: "10.0.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 3000
  
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi
  
  storage:
    enabled: true
    storageClass: "gp2"
    size: 10Gi
  
  config:
    security:
      admin_user: admin
      admin_password: admin123
    
    server:
      http_port: 3000
    
    database:
      type: sqlite3
      path: /var/lib/grafana/grafana.db
    
    log:
      mode: console
      level: info
    
    metrics:
      enabled: true
    
    analytics:
      reporting_enabled: false
      check_for_updates: false
  
  dashboards:
    # Query Engine Overview Dashboard
    - name: "query-engine-overview"
      title: "Query Engine Overview"
      uid: "query-engine-overview"
      panels:
        - title: "Query Latency"
          type: "graph"
          targets:
            - expr: "histogram_quantile(0.95, rate(query_duration_seconds_bucket[5m]))"
              legendFormat: "95th percentile"
        
        - title: "Query Throughput"
          type: "graph"
          targets:
            - expr: "rate(queries_total[5m])"
              legendFormat: "queries/sec"
        
        - title: "Error Rate"
          type: "graph"
          targets:
            - expr: "rate(query_errors_total[5m])"
              legendFormat: "errors/sec"
        
        - title: "Memory Usage"
          type: "graph"
          targets:
            - expr: "container_memory_usage_bytes{container!=\"\"}"
              legendFormat: "{{pod}}"
        
        - title: "CPU Usage"
          type: "graph"
          targets:
            - expr: "rate(container_cpu_usage_seconds_total{container!=\"\"}[5m]) * 100"
              legendFormat: "{{pod}}"
    
    # Presto/Trino Dashboard
    - name: "presto-dashboard"
      title: "Presto/Trino Dashboard"
      uid: "presto-dashboard"
      panels:
        - title: "Active Queries"
          type: "stat"
          targets:
            - expr: "presto_active_queries"
        
        - title: "Queued Queries"
          type: "stat"
          targets:
            - expr: "presto_queued_queries"
        
        - title: "Query Execution Time"
          type: "graph"
          targets:
            - expr: "histogram_quantile(0.95, rate(presto_query_execution_time_bucket[5m]))"
              legendFormat: "95th percentile"
    
    # ClickHouse Dashboard
    - name: "clickhouse-dashboard"
      title: "ClickHouse Dashboard"
      uid: "clickhouse-dashboard"
      panels:
        - title: "Query Count"
          type: "stat"
          targets:
            - expr: "rate(clickhouse_query_total[5m])"
        
        - title: "Query Duration"
          type: "graph"
          targets:
            - expr: "histogram_quantile(0.95, rate(clickhouse_query_duration_seconds_bucket[5m]))"
              legendFormat: "95th percentile"
        
        - title: "Merge Operations"
          type: "graph"
          targets:
            - expr: "rate(clickhouse_merge_operations_total[5m])"
              legendFormat: "merges/sec"

# Alertmanager configuration
alertmanager:
  enabled: true
  replicaCount: 1
  
  image:
    repository: prom/alertmanager
    tag: "v0.25.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 9093
  
  resources:
    limits:
      cpu: 500m
      memory: 1Gi
    requests:
      cpu: 250m
      memory: 500Mi
  
  storage:
    enabled: true
    storageClass: "gp2"
    size: 10Gi
  
  config:
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@example.com'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
    
    receivers:
      - name: 'web.hook'
        webhook_configs:
          - url: 'http://127.0.0.1:5001/'
    
    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'dev', 'instance']

# Node Exporter configuration
nodeExporter:
  enabled: true
  replicaCount: 1
  
  image:
    repository: prom/node-exporter
    tag: "v1.6.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 9100
  
  resources:
    limits:
      cpu: 200m
      memory: 100Mi
    requests:
      cpu: 100m
      memory: 50Mi

# Kube State Metrics configuration
kubeStateMetrics:
  enabled: true
  replicaCount: 1
  
  image:
    repository: registry.k8s.io/kube-state-metrics/kube-state-metrics
    tag: "v2.8.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
  
  resources:
    limits:
      cpu: 200m
      memory: 100Mi
    requests:
      cpu: 100m
      memory: 50Mi

# Service Monitor configuration
serviceMonitor:
  enabled: true
  
  # Presto Service Monitor
  presto:
    enabled: true
    interval: 30s
    path: /v1/metrics
    port: http
  
  # ClickHouse Service Monitor
  clickhouse:
    enabled: true
    interval: 30s
    path: /metrics
    port: http
  
  # Spark Service Monitor
  spark:
    enabled: true
    interval: 30s
    path: /metrics
    port: http

# Pod Monitor configuration
podMonitor:
  enabled: true
  
  # Query Engine Pod Monitor
  queryEngine:
    enabled: true
    interval: 30s
    path: /metrics
    port: http

# Health checks
livenessProbe:
  httpGet:
    path: /-/healthy
    port: 9090
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /-/ready
    port: 9090
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Pod disruption budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1
